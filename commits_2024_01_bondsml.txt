898907ae170d597e7c9d32a8033a806e1d43b66e MislavSag Thu Jan 25 16:37:31 2024 +0100 fixes
diff --git a/check_macro_variables.R b/check_macro_variables.R
new file mode 100644
index 0000000..74b194e
--- /dev/null
+++ b/check_macro_variables.R
@@ -0,0 +1,78 @@
+library(data.table)
+library(lubridate)
+library(forecast)
+library(fs)
+
+
+# TODO : move some of following steps to server
+
+# Import fred series
+list.files("F:/data/macro/fred")
+fred_dt = lapply(dir_ls("F:/data/macro/fred"), fread)
+fred_dt = rbindlist(fred_dt)
+
+# Check dupplicates. I just want to check how many duplicates area there
+# Otherwise, this is not necessary step. Later when I will move function to
+# server to make clean fred_dt I can remove this step.
+dup_realtime_start = fred_dt[, .N, by = .(series_id, realtime_start)]
+dup_realtime_start[, (sum(N) - nrow(dup_realtime_start)) / nrow(fred_dt)]
+duplicates_date = fred_dt[, .N, by = .(series_id, date)]
+duplicates_date[, (sum(N) - nrow(duplicates_date)) / nrow(fred_dt)]
+
+# Create date column
+fred_dt[, date_real := date]
+fred_dt[vintage == 1, date_real := realtime_start]
+fred_dt[, realtime_start := NULL]
+
+# keep unique dates by keeping first observation
+fred_dt = unique(fred_dt, by = c("series_id", "date_real"))
+
+# remove observations where there is no data 4 months before today
+cols_keep = fred_dt[ , .(keep = any(max(date) > (Sys.Date()-365/4))), by=series_id]
+cols_keep = cols_keep[keep == TRUE, series_id]
+fred_dt = fred_dt[series_id %in% cols_keep]
+
+# # remove unnecessary columns
+# fred_dt = fred_dt[, .(series_id, date_real = realtime_start, frequency_short,
+#                       popularity, units, id_category, value)]
+
+# downsample to monthly frequency
+fred_dt[, month := ceiling_date(date, "month")]
+fred_dt = fred_dt[, tail(.SD, 1), by = c("series_id", "month")]
+
+# reshape
+fred_dt = dcast(fred_dt[, .(month, series_id, value)],
+                month ~ series_id,
+                value.var = "value")
+
+# locf vars
+predictors = colnames(fred_dt)[2:ncol(fred_dt)]
+fred_dt[, (predictors) := lapply(.SD, nafill, type = "locf"), .SDcols = predictors]
+
+# We want to keep only columns that have dates for all observations after some date
+dates_start = c(as.Date("1961-06-01"),
+                as.Date("1980-01-01"),
+                as.Date("1990-01-01"),
+                as.Date("2000-01-01"))
+columns_save = list()
+for (i in seq_along(dates_start)) {
+  # filter dates
+  d = dates_start[i]
+  fred_dt_sample = fred_dt[month >= d]
+
+  # check for missing values
+  na_check = colSums(is.na(fred_dt_sample))
+  fred_dt_sample = fred_dt_sample[, .SD, .SDcols = na_check == 0]
+  columns_save[[i]] = fred_dt_sample[, .(start_date = d,
+                                         cols = colnames(fred_dt_sample)[-1])]
+}
+columns_save = rbindlist(columns_save)
+
+# final dt object with sampled data
+vars_keep = c("month", columns_save[, unique(cols)])
+fred_sample_by_date = fred_dt[, ..vars_keep]
+
+# save final objects
+fwrite(columns_save, "data/fred_col.csv")
+fwrite(fred_sample_by_date, "data/fred_sample_by_date.csv")
+
diff --git a/padobran_prepare.R b/padobran_prepare.R
index 9837d07..f88de12 100644
--- a/padobran_prepare.R
+++ b/padobran_prepare.R
@@ -6,6 +6,7 @@ library(paradox)
 library(AzureStor)
 library(mlr3batchmark)
 library(batchtools)
+library(finautoml)
 
 
 # downlaod data from Azure blob
@@ -13,7 +14,7 @@ blob_key = readLines('./blob_key.txt')
 endpoint = "https://snpmarketdata.blob.core.windows.net/"
 BLOBENDPOINT = storage_endpoint(endpoint, key=blob_key)
 cont = storage_container(BLOBENDPOINT, "padobran")
-dt = storage_read_csv(cont, "bonds-predictors.csv")
+  dt = storage_read_csv(cont, "bonds-predictors-20240125.csv")
 dt = as.data.table(dt)
 
 
@@ -26,6 +27,9 @@ task_params = expand.grid(
   stringsAsFactors = FALSE
 )
 colnames(task_params) = c("horizont", "maturity")
+task_params = task_params[task_params$horizont == "1", ]
+idx = as.integer(gsub("m", "", task_params$maturity)) > 12
+task_params = task_params[idx, ]
 
 # define predictors
 cols = colnames(dt)
@@ -55,14 +59,14 @@ tasks = lapply(1:nrow(task_params), function(i) {
 # CROSS VALIDATION --------------------------------------------------------
 # create expanding window function
 nested_cv_expanding = function(task,
-                               train_length_start = 60,
+                               train_length_start = 360,
                                tune_length = 3,
                                test_length = 1,
-                               gap_tune = 1,
-                               gap_test = 1) {
+                               gap_tune = 0,
+                               gap_test = 0) {
 
   # get year month id data
-  # task = tasks[[2]]$clone()
+  # task = tasks[[1]]$clone()
   task_ = task$clone()
   date_ = task_$backend$data(cols = c("date", "..row_id"),
                              rows = 1:task_$nrow)
@@ -143,7 +147,7 @@ cvs = lapply(tasks, function(tsk_) {
   horizont_ = as.integer(gsub("excess_return_", "", tsk_$target_names))
   nested_cv_expanding(
     task = tsk_,
-    train_length_start = 120,
+    train_length_start = 360,
     tune_length = 3,
     test_length = 1,
     gap_tune = horizont_ - 1, # TODO: think if here is -1.
@@ -154,30 +158,16 @@ cvs = lapply(tasks, function(tsk_) {
 
 # ADD PIPELINES -----------------------------------------------------------
 # source pipes, filters and other
-# source("mlr3_winsorization.R")
-source("mlr3_uniformization.R")
 source("mlr3_gausscov_f1st.R")
 source("mlr3_gausscov_f3st.R")
-# source("mlr3_dropna.R")
-# source("mlr3_dropnacol.R")
-source("mlr3_filter_drop_corr.R")
-# source("mlr3_winsorizationsimple.R")
-# source("mlr3_winsorizationsimplegroup.R")
-# source("PipeOpPCAExplained.R")
 # measures
 source("Linex.R")
 source("AdjLoss2.R")
 source("PortfolioRet.R")
 
 # add my pipes to mlr dictionary
-mlr_pipeops$add("uniformization", PipeOpUniform)
-# mlr_pipeops$add("winsorize", PipeOpWinsorize)
-# mlr_pipeops$add("winsorizesimple", PipeOpWinsorizeSimple)
-# mlr_pipeops$add("winsorizesimplegroup", PipeOpWinsorizeSimpleGroup)
-# mlr_pipeops$add("dropna", PipeOpDropNA)
-# mlr_pipeops$add("dropnacol", PipeOpDropNACol)
-mlr_pipeops$add("dropcorr", PipeOpDropCorr)
-# mlr_pipeops$add("pca_explained", PipeOpPCAExplained)
+mlr_pipeops$add("uniformization", finautoml::PipeOpUniform)
+mlr_pipeops$add("dropcorr", finautoml::PipeOpDropCorr)
 mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
 mlr_filters$add("gausscov_f3st", FilterGausscovF3st)
 mlr_measures$add("linex", Linex)
@@ -279,8 +269,6 @@ search_space_rf$add(
      regr.ranger.num.trees  = p_int(10, 2000),
      regr.ranger.splitrule  = p_fct(levels = c("variance", "extratrees")))
 )
-# regr.ranger.min.node.size   = p_int(1, 20), # Adjust the range as needed
-# regr.ranger.sample.fraction = p_dbl(0.1, 1),
 
 # xgboost graph
 graph_xgboost = graph_template %>>%
@@ -433,7 +421,7 @@ sh_file = sprintf("
 
 #PBS -N PEAD
 #PBS -l ncpus=4
-#PBS -l mem=8GB
+#PBS -l mem=4GB
 #PBS -J 1-%d
 #PBS -o experiments/logs
 #PBS -j oe
diff --git a/prepare_for_padobran.R b/prepare_bonds.R
similarity index 80%
rename from prepare_for_padobran.R
rename to prepare_bonds.R
index fd7f760..a78e109 100644
--- a/prepare_for_padobran.R
+++ b/prepare_bonds.R
@@ -83,38 +83,43 @@ excess_returns(12)
 
 
 # MACRO DATA --------------------------------------------------------------
-# import fred series
-fred_dt = fread("F:/macro/fred.csv")
+# TODO : Simplify this after macro data are downloaded
 
-# remove unnecessary columns
-fred_dt = fred_dt[, .(series_id, date = date_real, frequency_short, popularity,
-                      units, id_category, value)]
+# import data we need
+fred_columns = fread("data/fred_columns.csv")
+fred_columns = fred_columns[start_date == min(start_date), cols]
+
+# Import fred series
+pah_fred = "F:/data/macro/fred/"
+files_ = paste0(pah_fred, fred_columns, ".csv")
+fred_dt = lapply(files_, fread)
+fred_dt = rbindlist(fred_dt)
+
+# Create date column
+fred_dt[, date_real := date]
+fred_dt[vintage == 1, date_real := realtime_start]
+fred_dt[, realtime_start := NULL]
+
+# keep unique dates by keeping first observation
+fred_dt = unique(fred_dt, by = c("series_id", "date_real"))
 
 # diff if necessary
 fred_dt = fred_dt[, ndif := ndiffs(value), by = series_id]
 fred_dt[, unique(ndif), by = series_id][, .N, by = V1]
 fred_dt[ndif > 0, value_diff := c(rep(NA, unique(ndif)), diff(value, unique(ndif))), by = series_id]
 
-# check for duplicates
-date_series = fred_dt[, .N, by = .(date, series_id)]
-fred_dt = unique(fred_dt, fromLast = TRUE, by = c("series_id", "date"))
-rm(date_series)
-
 # downsample to monthly frequency
 fred_dt[, month := ceiling_date(date, "month")]
 fred_dt = fred_dt[, tail(.SD, 1), by = c("series_id", "month")]
 
 # reshape
-fred_dt = dcast(fred_dt[, .(month, series_id, value_diff)],
+fred_dt = dcast(fred_dt[, .(month, series_id, value)],
                 month ~ series_id,
-                value.var = "value_diff")
-setnames(fred_dt, "month", "date")
-setorder(fred_dt, date)
-fred_dt[1:10, 1:10]
+                value.var = "value")
 
-# remove predictors that doesnt have data for last year
-na_check_last_year = colSums(is.na(tail(fred_dt, 12)))
-fred_dt = fred_dt[, .SD, .SDcols = na_check_last_year < 12]
+# add missing dates
+dates = data.table(month = seq.Date(fred_dt[, min(month)], fred_dt[, max(month)], by = "month"))
+fred_dt = fred_dt[dates, on = "month"]
 
 # locf vars
 predictors = colnames(fred_dt)[2:ncol(fred_dt)]
@@ -124,22 +129,18 @@ fred_dt[, (predictors) := lapply(.SD, nafill, type = "locf"), .SDcols = predicto
 # fred_dt[, (predictors) := lapply(.SD, shift), .SDcols = predictors]
 
 # filter dates
-fred_dt = fred_dt[date >= lw[, min(date)]]
-fred_dt[1:10, 1:10]
+fred_dt = fred_dt[month >= lw[, min(date)]]
 
-# check for missing values
-na_check = colSums(is.na(fred_dt))
-sum(na_check == 0)
-fred_dt[, .SD, .SDcols = na_check == 0]
-fred_dt_sample = fred_dt[, .SD, .SDcols = na_check == 0]
+# change colun name to be the same as in other objects
+setnames(fred_dt, "month", "date")
 
 # predictors fred
-predictors_fred = colnames(fred_dt_sample)[2:ncol(fred_dt_sample)]
+predictors_fred = colnames(fred_dt)[2:ncol(fred_dt)]
 
 
 # PREDICTORS --------------------------------------------------------------
 # merge yields and macro data
-dt = merge(yieldsadj, fred_dt_sample, by = "date", all.x = TRUE, all.y = FALSE)
+dt = merge(yieldsadj, fred_dt, by = "date", all.x = TRUE, all.y = FALSE)
 
 # momentum predictors
 setorder(dt, maturity, date)
@@ -173,4 +174,6 @@ endpoint = "https://snpmarketdata.blob.core.windows.net/"
 blob_key = "0M4WRlV0/1b6b3ZpFKJvevg4xbC/gaNBcdtVZW+zOZcRi0ZLfOm1v/j2FZ4v+o8lycJLu1wVE6HT+ASt0DdAPQ=="
 BLOBENDPOINT = storage_endpoint(endpoint, key=blob_key)
 cont = storage_container(BLOBENDPOINT, "padobran")
-storage_write_csv(dt, cont, "bonds-predictors.csv")
+time_ = strftime(Sys.time(), format = "%Y%m%d")
+file_name = paste0("bonds-predictors-", time_, ".csv")
+storage_write_csv(dt, cont, file_name)
diff --git a/results.R b/results.R
index c641062..adc7be6 100644
--- a/results.R
+++ b/results.R
@@ -13,7 +13,7 @@ get_sec = function(symbol) {
   con <- dbConnect(duckdb::duckdb())
   query <- sprintf("
     SELECT *
-    FROM 'F:/lean_root/data/all_stocks_daily.csv'
+    FROM 'F:/lean/data/stocks_daily.csv'
     WHERE Symbol = '%s'
 ", symbol)
   data_ <- dbGetQuery(con, query)
diff --git a/results_com.R b/results_com.R
index f052f96..4ac140f 100644
--- a/results_com.R
+++ b/results_com.R
@@ -4,17 +4,22 @@ library(fs)
 library(duckdb)
 library(lubridate)
 library(PerformanceAnalytics)
+library(janitor)
 
 
 
 # commodity data ----------------------------------------------------------------
+# import commodity prices
+commodity_prices = fread("data/commodity_prices.csv")
+commodity_prices = clean_names(commodity_prices)
+commodity_prices[, month := as.Date(paste(gsub("M", "", month), "01"), format = "%Y%m%d")]
 
 
 
 # PREDICTIONS -------------------------------------------------------------
 # list files
-mlr3_save_path = file.path(file.path(getwd(), "data/results"))
-files = list.files("data/results", full.names = TRUE)
+mlr3_save_path = file.path(file.path(getwd(), "data"))
+files = list.files(mlr3_save_path, full.names = TRUE, pattern = "commodities-")
 
 # read benchmark results
 predictions_l = list()
@@ -45,10 +50,12 @@ for (i in 1:length(files)) {
   learner_names = lapply(bmr_dt$learner, `[[`, "id")
   learner_names = gsub(".*\\.regr\\.|\\.tuned", "", learner_names)
   predictions = lapply(bmr_dt$prediction, function(x) as.data.table(x))
+  horizont = lapply(bmr_dt$task, `[[`, "target_names")
   predictions = lapply(seq_along(predictions), function(j)
     cbind(task = task_names[[j]],
           learner = learner_names[[j]],
-          predictions[[j]]))
+          predictions[[j]],
+          horizont = horizont[[j]]))
   predictions = rbindlist(predictions)
 
   # merge backs and predictions
@@ -58,13 +65,13 @@ for (i in 1:length(files)) {
   predictions = backend[predictions, on = c("row_ids")]
 
   # select cols
-  cols = c("row_ids", "maturity", "task", "learner", "truth", "response", "date")
+  cols = c("row_ids", "var", "horizont", "task", "learner", "truth", "response", "month")
   predictions = predictions[, ..cols]
-  predictions[, month := as.Date(date)]
+  # predictions[, month := as.Date(date)]
   predictions_l[[i]] = predictions
 }
 predictions = rbindlist(predictions_l)
-predictions[, horizont := as.integer(gsub(".*_", "", task))]
+predictions[, horizont := as.integer(gsub(".*_", "", horizont))]
 predictions[, unique(task)]
 
 
@@ -79,7 +86,7 @@ Performance <- function(dt) {
 
   res = rbind(cumRetx, annRetx)
   res = as.data.table(res, keep.rownames = "var")
-  res[, mat := dt[1, mat]]
+  # res[, mat := dt[1, mat]]
 
   # sharpex = SharpeRatio.annualized(x, scale=12)
   # winpctx = length(x[x > 0])/length(x[x != 0])
@@ -97,33 +104,38 @@ Performance <- function(dt) {
 
 
 # backtest function
-backtest = function(task, mat) {
-  # task = backtest_dt[task == "m1_1"]
-  # mat = "m1_1"
+backtest = function(task, var) {
+  # task = predictions[var == "gold"]
+  # hor = 1
   predictions_wide = task[, .(month, learner, response)]
   predictions_wide = dcast(predictions_wide, month ~ learner, value.var = "response")
   predictions_wide[, res_sum := ranger + xgboost]
   predictions_wide[, signal_ranger := ranger >= 0]
   predictions_wide[, signal_xgboost := xgboost >= 0]
   predictions_wide[, signal_sum := (xgboost + ranger) >= 0]
-  tlt_back = merge(tlt_m, predictions_wide, by = "month", all.x = TRUE, all.y = FALSE)
-  tlt_back = tlt_back[, `:=`(
+  predictions_wide[, month := as.Date(month)]
+  cols = c("month", var)
+  print(cols)
+  commodity_ = commodity_prices[, ..cols]
+  back_ = merge(commodity_, predictions_wide, by = "month", all.x = TRUE, all.y = FALSE)
+  back_[, returns := get(var) / shift(get(var)) - 1]
+  back_ = back_[, `:=`(
     strategy_ranger = returns * shift(signal_ranger),
     strategy_xgboost = returns * shift(signal_xgboost),
     signal_sum = returns * shift(signal_sum)
   )]
   cols = c("month", "returns", "strategy_ranger", "strategy_xgboost",
            "signal_sum")
-  tlt_back = tlt_back[, ..cols]
-  tlt_back = na.omit(tlt_back)
-  tlt_back[, mat := mat]
-  # tlt_back = na.omit(as.xts.data.table(tlt_back))
-  # colnames(tlt_back) = paste0(colnames(tlt_back), "_", task[1, 2])
-  tlt_back
+  back_ = back_[, ..cols]
+  back_ = na.omit(back_)
+  # back_[, mat := mat]
+  # # tlt_back = na.omit(as.xts.data.table(tlt_back))
+  # # colnames(tlt_back) = paste0(colnames(tlt_back), "_", task[1, 2])
+  return(back_)
 }
 
 # backtest grid
-performance = predictions[, .(returns = list(backtest(.SD, .BY))), by = "task"]
+performance = predictions[, .(returns = list(backtest(.SD, .BY[[1]]))), by = c("task")]
 performance = performance[, do.call(rbind, lapply(returns, Performance))]
 
 # individual backtests
diff --git a/results_padobran.R b/results_padobran.R
new file mode 100644
index 0000000..7393b6b
--- /dev/null
+++ b/results_padobran.R
@@ -0,0 +1,243 @@
+library(fs)
+library(data.table)
+library(mlr3verse)
+library(mlr3batchmark)
+library(batchtools)
+library(duckdb)
+library(PerformanceAnalytics)
+library(AzureStor)
+library(future.apply)
+library(lubridate)
+library(ggplot2)
+
+
+# creds
+blob_key = "0M4WRlV0/1b6b3ZpFKJvevg4xbC/gaNBcdtVZW+zOZcRi0ZLfOm1v/j2FZ4v+o8lycJLu1wVE6HT+ASt0DdAPQ=="
+endpoint = "https://snpmarketdata.blob.core.windows.net/"
+BLOBENDPOINT = storage_endpoint(endpoint, key=blob_key)
+
+# globals
+PATH = "F:/padobran/bonds_ml/"
+
+# load registry
+reg = loadRegistry(PATH, work.dir=PATH)
+
+# used memory
+reg$status[!is.na(mem.used)]
+reg$status[, max(mem.used, na.rm = TRUE)]
+
+# done jobs
+results_files = fs::path_ext_remove(fs::path_file(dir_ls(fs::path(PATH, "results"))))
+ids_done = findDone(reg=reg)
+ids_done = ids_done[job.id %in% results_files]
+ids_notdone = findNotDone(reg=reg)
+
+# get results
+tabs = batchtools::getJobTable(ids_done, reg = reg)[
+  , c("job.id", "job.name", "repl", "prob.pars", "algo.pars"), with = FALSE]
+predictions_meta = cbind.data.frame(
+  id = tabs[, job.id],
+  task = vapply(tabs$prob.pars, `[[`, character(1L), "task_id"),
+  learner = gsub(".*regr.|.tuned", "", vapply(tabs$algo.pars, `[[`, character(1L), "learner_id")),
+  cv = gsub("custom_|_.*", "", vapply(tabs$prob.pars, `[[`, character(1L), "resampling_id")),
+  fold = gsub("custom_\\d+_", "", vapply(tabs$prob.pars, `[[`, character(1L), "resampling_id"))
+)
+predictions_l = lapply(unlist(ids_done), function(id_) {
+  # id_ = 10035
+  x = tryCatch({readRDS(fs::path(PATH, "results", id_, ext = "rds"))},
+               error = function(e) NULL)
+  if (is.null(x)) {
+    print(id_)
+    return(NULL)
+  }
+  x["id"] = id_
+  x
+})
+predictions = lapply(predictions_l, function(x) {
+  cbind.data.frame(
+    id = x$id,
+    row_ids = x$prediction$test$row_ids,
+    truth = x$prediction$test$truth,
+    response = x$prediction$test$response
+  )
+})
+predictions = rbindlist(predictions)
+predictions = merge(predictions_meta, predictions, by = "id")
+predictions = as.data.table(predictions)
+
+# import tasks
+tasks_files = dir_ls(fs::path(PATH, "problems"))
+tasks = lapply(tasks_files, readRDS)
+names(tasks) = lapply(tasks, function(t) t$data$id)
+tasks
+
+# add backend to predictions
+backend_l = lapply(tasks, function(tsk_) {
+  x = tsk_$data$backend$data(1:tsk_$data$nrow,
+                             c("date", "maturity", "..row_id"))
+  setnames(x, c("date", "maturity", "row_ids"))
+  x[, horizont := gsub("excess_return_", "", tsk_$data$target_names)]
+  x
+})
+backends = rbindlist(backend_l, fill = TRUE)
+backends[, .N, by = horizont]
+backends[, task := paste0(maturity, "_", horizont)]
+
+# merge predictions and backends
+predictions = backends[, .(date, task, row_ids)][predictions, on = c("task", "row_ids")]
+
+# measures
+source("Linex.R")
+source("AdjLoss2.R")
+source("PortfolioRet.R")
+mlr_measures$add("linex", Linex)
+mlr_measures$add("adjloss2", AdjLoss2)
+mlr_measures$add("portfolio_ret", PortfolioRet)
+
+# merge backs and predictions
+predictions[, date := as.Date(date)]
+
+
+# TLT DATA ----------------------------------------------------------------
+# get securities data from QC
+get_sec = function(symbol) {
+  con <- dbConnect(duckdb::duckdb())
+  query <- sprintf("
+    SELECT *
+    FROM 'F:/lean/data/stocks_daily.csv'
+    WHERE Symbol = '%s'
+", symbol)
+  data_ <- dbGetQuery(con, query)
+  dbDisconnect(con)
+  data_ = as.data.table(data_)
+  data_ = data_[, .(date = Date, close = `Adj Close`)]
+  data_[, returns := close / shift(close) - 1]
+  data_ = na.omit(data_)
+  return(data_)
+}
+tlt_dt = get_sec("tlt")
+
+# downsample TLT to monthly
+tlt_m = copy(tlt_dt)
+tlt_m[, month := ceiling_date(date, "month")]
+# tlt_m[, close := tail(close, 1), by = month]
+tlt_m = tlt_m[, tail(.SD, 1), by = month]
+tlt_m[, returns := close / shift(close) - 1]
+tlt_m = na.omit(tlt_m)
+
+
+# BACKTEST ----------------------------------------------------------------
+# define backtest data that merge TLT and predictions
+backtest_dt = merge(tlt_m, predictions, by.x = "month", by.y = "date", all.x = TRUE, all.y = FALSE)
+backtest_dt = na.omit(backtest_dt, cols = "task")
+
+# benchamrk return (TLT return)
+benchmark_performance = tlt_m[,
+  .(returns = Return.cumulative(returns), ann_returns = Return.annualized(returns, scale = 12))
+]
+
+# portfoli performance
+Performance <- function(dt) {
+  # dt = performance[2, returns][[1]]
+  xts_ = as.xts.data.table(dt[, .SD, .SDcols = 1:(ncol(dt)-1)])
+
+  cumRetx = Return.cumulative(xts_)
+  annRetx = Return.annualized(xts_, scale=12)
+
+  res = rbind(cumRetx, annRetx)
+  res = as.data.table(res, keep.rownames = "var")
+  res[, mat := dt[1, mat]]
+
+  # sharpex = SharpeRatio.annualized(x, scale=12)
+  # winpctx = length(x[x > 0])/length(x[x != 0])
+  # annSDx = sd.annualized(x, scale=12)
+
+  # DDs <- findDrawdowns(x)
+  # maxDDx = min(DDs$return)
+  # maxLx = max(DDs$length)
+
+  # Perf = c(cumRetx, annRetx, sharpex, winpctx, annSDx, maxDDx, maxLx)
+  # names(Perf) = c("Cumulative Return", "Annual Return","Annualized Sharpe Ratio",
+  #                 "Win %", "Annualized Volatility", "Maximum Drawdown", "Max Length Drawdown")
+  # return(Perf)
+}
+
+# backtest function
+backtest = function(task, mat) {
+  print(mat)
+  # task = backtest_dt[task == "m1_1"]
+  # mat = "m1_1"
+  predictions_wide = task[, .(month, learner, response)]
+  predictions_wide = dcast(predictions_wide, month ~ learner, value.var = "response")
+  predictions_wide[, res_sum := ranger + xgboost]
+  predictions_wide[, signal_ranger := ranger >= 0]
+  predictions_wide[, signal_xgboost := xgboost >= 0]
+  predictions_wide[, signal_sum := (xgboost + ranger) >= 0]
+  tlt_back = merge(tlt_m, predictions_wide, by = "month", all.x = TRUE, all.y = FALSE)
+  tlt_back = tlt_back[, `:=`(
+    strategy_ranger = returns * shift(signal_ranger),
+    strategy_xgboost = returns * shift(signal_xgboost),
+    signal_sum = returns * shift(signal_sum)
+  )]
+  cols = c("month", "returns", "strategy_ranger", "strategy_xgboost",
+           "signal_ranger", "signal_xgboost","signal_sum")
+  tlt_back = tlt_back[, ..cols]
+  tlt_back = na.omit(tlt_back)
+  tlt_back[, mat := mat]
+  # tlt_back = na.omit(as.xts.data.table(tlt_back))
+  # colnames(tlt_back) = paste0(colnames(tlt_back), "_", task[1, 2])
+  tlt_back
+}
+
+# backtest grid
+performance = backtest_dt[, .(returns = list(backtest(.SD, .BY))), by = "task"]
+performance_dt = performance[, do.call(rbind, lapply(returns, Performance))]
+performance_dt[var == "Cumulative Return"][order(signal_sum)]
+benchmark_performance$returns
+
+# visualize histogram of perfromances by signal_sum and add vertical line for benchmark
+ggplot(performance_dt[var == "Cumulative Return"], aes(signal_sum)) +
+  geom_histogram(bins = 50) +
+  geom_vline(xintercept = benchmark_performance$returns, color = "red")
+  # facet_wrap(~ mat, ncol = 2)
+
+# performance acroos maturity and horizont
+performance[, `:=`(
+  maturiy = as.factor(gsub("m|_.*", "", mat)),
+  horizont = as.factor(gsub(".*_", "", mat))
+)]
+performance[, unique(maturiy)]
+lvls = c("1", "2", "3", "4", "6", "12", "24", "36", "60", "120", "240", "360")
+performance[, maturiy := factor(maturiy, levels = lvls)]
+performance[, unique(horizont)]
+performance[, horizont := factor(horizont, levels = c("1", "3", "6", "12"))]
+ggplot(performance[var == "Cumulative Return"], aes(maturiy, signal_sum)) +
+  geom_boxplot() +
+  facet_wrap(~ horizont, ncol = 4)
+
+# individual backtests
+best_ind = performance_dt[var == "Cumulative Return", which.max(signal_sum)]
+best = performance[best_ind, returns][[1]]
+charts.PerformanceSummary(as.xts.data.table(best[, 1:5]))
+
+
+# ENSAMBLE METHODS --------------------------------------------------------
+# ensamble for one month
+predictions_ensamble = backtest_dt[gsub(".*_", "", task) == 1, .(month, learner, response)]
+predictions_ensamble = predictions_ensamble[, .(response = sum(response)), by = month]
+predictions_ensamble[, signal_strat := response >= 0]
+tlt_back = merge(tlt_m, predictions_ensamble, by = "month", all.x = TRUE, all.y = FALSE)
+tlt_back = tlt_back[, `:=`(strategy = returns * shift(signal_strat))]
+cols = c("month", "returns", "strategy")
+tlt_back = tlt_back[, ..cols]
+tlt_back = na.omit(tlt_back)
+charts.PerformanceSummary(as.xts.data.table(tlt_back))
+
+
+# QC PREPARE --------------------------------------------------------------
+# preapre data or QC and save
+qc_data = predictions_ensamble[, .(month, strategy = signal_strat)]
+endpoint = "https://snpmarketdata.blob.core.windows.net/"
+BLOBENDPOINT = storage_endpoint(endpoint, key="0M4WRlV0/1b6b3ZpFKJvevg4xbC/gaNBcdtVZW+zOZcRi0ZLfOm1v/j2FZ4v+o8lycJLu1wVE6HT+ASt0DdAPQ==")
+cont = storage_container(BLOBENDPOINT, "qc-backtest")
+storage_write_csv(qc_data, cont, "tlt_forecasts.csv") # , col_names = FALSE

6378942ced9b5a030bb26c27f3f9179b0a3cae47 unknown Fri Jan 5 14:50:51 2024 +0100 add arraays
diff --git a/.gitignore b/.gitignore
index ec12cdb..f4bffbd 100644
--- a/.gitignore
+++ b/.gitignore
@@ -3,3 +3,4 @@
 .RData
 .Ruserdata
 data
+gausscov_f3
diff --git a/commodiies_ml.R b/commodiies_ml.R
new file mode 100644
index 0000000..a80f062
--- /dev/null
+++ b/commodiies_ml.R
@@ -0,0 +1,447 @@
+library(data.table)
+library(gausscov)
+library(httr)
+library(mlr3verse)
+library(paradox)
+# library(AzureStor)
+# library(mlr3batchmark)
+# library(batchtools)
+
+
+
+# IMPORT DATA -------------------------------------------------------------
+# get data generated in prepare_commodities
+dt = fread("data/commodities_dt.csv")
+
+
+# TASKS --------------------------------------------------------
+# task parameters
+cols = colnames(dt)
+task_params = expand.grid(gsub("excess_return_", "", cols[grep("target", cols)]),
+                          dt[, unique(var)],
+                          stringsAsFactors = FALSE)
+colnames(task_params) = c("targets", "commodity")
+
+# define predictors
+cols = colnames(dt)
+predictors = cols[(which(cols == "target_ret_12") + 1):length(cols)]
+
+# help function to prepare data for specific maturity and horizont
+id_cols = c("month", "var")
+tasks = lapply(1:nrow(task_params), function(i) {
+  # i = 1
+  target_ = task_params[i, "targets"]
+  var_ = task_params[i, "commodity"]
+  cols_ = c(id_cols, target_, predictors)
+  dt_ = dt[, ..cols_]
+  dt_ = dt_[var == var_]
+  dt_ = na.omit(dt_)
+  dt_[, month := as.POSIXct(month, tz = "UTC")]
+  tsk_ = as_task_regr(dt_,
+                      id = paste(var_, sep = "_"),
+                      target = target_)
+  tsk_$col_roles$feature = setdiff(tsk_$col_roles$feature,
+                                   id_cols)
+  tsk_
+})
+
+
+# CROSS VALIDATION --------------------------------------------------------
+# create expanding window function
+nested_cv_expanding = function(task,
+                               train_length_start = 60,
+                               tune_length = 3,
+                               test_length = 1,
+                               gap_tune = 1,
+                               gap_test = 1) {
+  # get year month id data
+  # task = tasks[[2]]$clone()
+  task_ = task$clone()
+  date_ = task_$backend$data(cols = c("month", "..row_id"),
+                             rows = 1:task_$nrow)
+  stopifnot(all(task_$row_ids == date_$`..row_id`))
+  groups_v = date_[, unlist(unique(month))]
+
+  # create cusom CV's for inner and outer sampling
+  custom_inner = rsmp("custom", id = task_$id)
+  custom_outer = rsmp("custom", id = task_$id)
+
+  # util vars
+  get_row_ids = function(mid)
+    unlist(date_[month %in% mid, 2], use.names = FALSE)
+  n = task_$nrow
+  mondf = function(d1, d2) {
+    monnb(d2) - monnb(d1)
+  }
+  monnb = function(d) {
+    lt <- as.POSIXlt(as.Date(d, origin = "1900-01-01"))
+    lt$year * 12 + lt$mon
+  }
+
+  # create train data
+  train_groups = lapply(train_length_start:n, function(i)
+    groups_v[1:i])
+
+  # create tune set
+  tune_groups <-
+    lapply((train_length_start + gap_tune + 1):n, function(i)
+      groups_v[i:(i + tune_length - 1)])
+  index_keep = vapply(tune_groups, function(x)
+    ! any(is.na(x)), FUN.VALUE = logical(1L))
+  tune_groups = tune_groups[index_keep]
+
+  # equalize train and tune sets
+  train_groups = train_groups[1:length(tune_groups)]
+
+  # create test sets
+  insample_length = vapply(train_groups, function(x)
+    as.integer(length(x) + gap_tune + tune_length + gap_test),
+    FUN.VALUE = integer(1))
+  test_groups <-
+    lapply(insample_length + 1, function(i)
+      groups_v[i:(i + test_length - 1)])
+  index_keep = vapply(test_groups, function(x)
+    ! any(is.na(x)), FUN.VALUE = logical(1L))
+  test_groups = test_groups[index_keep]
+
+  # equalize train, tune and test sets
+  train_groups = train_groups[1:length(test_groups)]
+  tune_groups = tune_groups[1:length(test_groups)]
+
+  # make sets
+  train_sets <- lapply(train_groups, get_row_ids)
+  tune_sets <- lapply(tune_groups, get_row_ids)
+  test_sets <- lapply(test_groups, get_row_ids)
+
+  # test tune and test
+  test_1 = vapply(seq_along(train_groups), function(i) {
+    mondf(tail(as.Date(train_groups[[i]], origin = "1970-01-01"), 1),
+          head(as.Date(tune_groups[[i]], origin = "1970-01-01"), 1))
+  }, FUN.VALUE = numeric(1L))
+  stopifnot(all(test_1 == 1 + gap_tune))
+  test_2 = vapply(seq_along(train_groups), function(i) {
+    mondf(tail(as.Date(tune_groups[[i]], origin = "1970-01-01"), 1),
+          head(as.Date(test_groups[[i]], origin = "1970-01-01"), 1))
+  }, FUN.VALUE = numeric(1L))
+  stopifnot(all(test_2 == 1 + gap_test))
+  test_3 = vapply(seq_along(train_groups), function(i) {
+    unlist(head(test_sets[[i]], 1) - tail(tune_sets[[i]], 1))
+  }, FUN.VALUE = numeric(1L))
+  stopifnot(all(test_3 == 1 + gap_test))
+
+  # create inner and outer resamplings
+  custom_inner$instantiate(task_, train_sets, tune_sets)
+  inner_sets = lapply(seq_along(train_groups), function(i) {
+    c(train_sets[[i]], tune_sets[[i]])
+  })
+  custom_outer$instantiate(task_, inner_sets, test_sets)
+  return(list(custom_inner = custom_inner, custom_outer = custom_outer))
+}
+
+# create list of cvs
+cvs = lapply(tasks, function(tsk_) {
+  # tsk_ = tasks[[1]]
+  horizont_ = as.integer(gsub("target_ret_", "", tsk_$target_names))
+  nested_cv_expanding(
+    task = tsk_,
+    train_length_start = 120,
+    tune_length = 3,
+    test_length = 1,
+    gap_tune = horizont_ - 1,
+    # TODO: think if here is -1.
+    gap_test = horizont_ - 1  # TODO: think if here is -1.
+  )
+})
+
+
+# ADD PIPELINES -----------------------------------------------------------
+# source pipes, filters and other
+# source("mlr3_winsorization.R")
+source("mlr3_uniformization.R")
+source("mlr3_gausscov_f1st.R")
+source("mlr3_gausscov_f3st.R")
+# source("mlr3_dropna.R")
+# source("mlr3_dropnacol.R")
+source("mlr3_filter_drop_corr.R")
+# source("mlr3_winsorizationsimple.R")
+# source("mlr3_winsorizationsimplegroup.R")
+# source("PipeOpPCAExplained.R")
+# measures
+source("Linex.R")
+source("AdjLoss2.R")
+source("PortfolioRet.R")
+
+# add my pipes to mlr dictionary
+mlr_pipeops$add("uniformization", PipeOpUniform)
+# mlr_pipeops$add("winsorize", PipeOpWinsorize)
+# mlr_pipeops$add("winsorizesimple", PipeOpWinsorizeSimple)
+# mlr_pipeops$add("winsorizesimplegroup", PipeOpWinsorizeSimpleGroup)
+# mlr_pipeops$add("dropna", PipeOpDropNA)
+# mlr_pipeops$add("dropnacol", PipeOpDropNACol)
+mlr_pipeops$add("dropcorr", PipeOpDropCorr)
+# mlr_pipeops$add("pca_explained", PipeOpPCAExplained)
+mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
+mlr_filters$add("gausscov_f3st", FilterGausscovF3st)
+mlr_measures$add("linex", Linex)
+mlr_measures$add("adjloss2", AdjLoss2)
+mlr_measures$add("portfolio_ret", PortfolioRet)
+
+
+# LEARNERS ----------------------------------------------------------------
+# graph template
+gr = gunion(list(
+  po("nop", id = "nop_union_pca"),
+  po("pca", center = FALSE, rank. = 10),
+  po("ica", n.comp = 10)
+)) %>>% po("featureunion")
+graph_template =
+  # po("subsample") %>>% # uncomment this for hyperparameter tuning
+  # po("dropnacol", id = "dropnacol", cutoff = 0.05) %>>%
+  # po("dropna", id = "dropna") %>>%
+  po("removeconstants", id = "removeconstants_1", ratio = 0)  %>>%
+  po("fixfactors", id = "fixfactors") %>>%
+  # po("winsorizesimple", id = "winsorizesimple", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE) %>>%
+  # po("winsorizesimplegroup", group_var = "weekid", id = "winsorizesimplegroup", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE) %>>%
+  # po("removeconstants", id = "removeconstants_2", ratio = 0)  %>>%
+  po("dropcorr", id = "dropcorr", cutoff = 0.99) %>>%
+  # scale branch
+  po("branch",
+     options = c("uniformization", "scale"),
+     id = "scale_branch") %>>%
+  gunion(list(po("uniformization"),
+              po("scale"))) %>>%
+  po("unbranch", id = "scale_unbranch") %>>%
+  # po("dropna", id = "dropna_v2") %>>%
+  # add pca columns
+  gr %>>%
+  # filters
+  po("branch",
+     options = c("jmi", "relief", "gausscovf3"),
+     id = "filter_branch") %>>%
+  gunion(list(
+    po("filter", filter = flt("jmi"), filter.nfeat = 10),
+    po(
+      "filter",
+      filter = flt("relief"),
+      filter.nfeat = 10
+    ),
+    po(
+      "filter",
+      filter = flt("gausscov_f3st"),
+      m = 1,
+      p0 = 0.01,
+      filter.cutoff = 0
+    )
+    # po("filter", filter = flt("gausscov_f1st"), filter.cutoff = 0)
+  )) %>>%
+  po("unbranch", id = "filter_unbranch") %>>%
+  # modelmatrix
+  po("branch",
+     options = c("nop_interaction", "modelmatrix"),
+     id = "interaction_branch") %>>%
+  gunion(list(
+    po("nop", id = "nop_interaction"),
+    po("modelmatrix", formula = ~ . ^ 2)
+  )) %>>%
+  po("unbranch", id = "interaction_unbranch") %>>%
+  po("removeconstants", id = "removeconstants_3", ratio = 0)
+
+# hyperparameters template
+graph_template$param_set
+search_space_template = ps(
+  # subsample for hyperband
+  # subsample.frac = p_dbl(0.3, 1, tags = "budget"), # unccoment this if we want to use hyperband optimization
+  # preprocessing
+  # dropnacol.affect_columns = p_fct(
+  #   levels = c("0.01", "0.05", "0.10"),
+  #   trafo = function(x, param_set) {
+  #     switch(x,
+  #            "0.01" = 0.01,
+  #            "0.05" = 0.05,
+  #            "0.10" = 0.1)
+  #   }
+  # ),
+  dropcorr.cutoff = p_fct(
+    levels = c("0.80", "0.90", "0.95", "0.99"),
+    trafo = function(x, param_set) {
+      switch(
+        x,
+        "0.80" = 0.80,
+        "0.90" = 0.90,
+        "0.95" = 0.95,
+        "0.99" = 0.99
+      )
+    }
+  ),
+  # dropcorr.cutoff = p_fct(levels = c(0.8, 0.9, 0.95, 0.99)),
+  # winsorizesimplegroup.probs_high = p_fct(levels = c(0.999, 0.99, 0.98, 0.97, 0.90, 0.8)),
+  # winsorizesimplegroup.probs_low = p_fct(levels = c(0.001, 0.01, 0.02, 0.03, 0.1, 0.2)),
+  # winsorizesimple.probs_high = p_fct(levels = c(0.999, 0.99, 0.98, 0.97, 0.90, 0.8)),
+  # winsorizesimple.probs_low = p_fct(levels = c(0.001, 0.01, 0.02, 0.03, 0.1, 0.2)),
+  # scaling
+  scale_branch.selection = p_fct(levels = c("uniformization", "scale")),
+  # filters
+  filter_branch.selection = p_fct(levels = c("jmi", "relief", "gausscovf3")),
+  # interaction
+  interaction_branch.selection = p_fct(levels = c("nop_interaction", "modelmatrix"))
+)
+
+# random forest graph
+graph_rf = graph_template %>>%
+  po("learner", learner = lrn("regr.ranger"))
+plot(graph_rf)
+graph_rf = as_learner(graph_rf)
+as.data.table(graph_rf$param_set)[, .(id, class, lower, upper, levels)]
+search_space_rf = search_space_template$clone()
+search_space_rf$add(
+  ps(
+    regr.ranger.max.depth  = p_int(1, 15),
+    regr.ranger.replace    = p_lgl(),
+    regr.ranger.mtry.ratio = p_dbl(0.1, 1),
+    regr.ranger.num.trees  = p_int(10, 2000),
+    regr.ranger.splitrule  = p_fct(levels = c("variance", "extratrees"))
+  )
+)
+# regr.ranger.min.node.size   = p_int(1, 20), # Adjust the range as needed
+# regr.ranger.sample.fraction = p_dbl(0.1, 1),
+
+# xgboost graph
+graph_xgboost = graph_template %>>%
+  po("learner", learner = lrn("regr.xgboost"))
+plot(graph_xgboost)
+graph_xgboost = as_learner(graph_xgboost)
+as.data.table(graph_xgboost$param_set)[grep("depth", id), .(id, class, lower, upper, levels)]
+search_space_xgboost = ps(
+  # subsample for hyperband
+  # subsample.frac = p_dbl(0.3, 1, tags = "budget"), # unccoment this if we want to use hyperband optimization
+  # preprocessing
+  # dropnacol.affect_columns = p_fct(
+  #   levels = c("0.01", "0.05", "0.10"),
+  #   trafo = function(x, param_set) {
+  #     switch(x,
+  #            "0.01" = 0.01,
+  #            "0.05" = 0.05,
+  #            "0.10" = 0.1)
+  #   }
+  # ),
+  dropcorr.cutoff = p_fct(
+    levels = c("0.80", "0.90", "0.95", "0.99"),
+    trafo = function(x, param_set) {
+      switch(
+        x,
+        "0.80" = 0.80,
+        "0.90" = 0.90,
+        "0.95" = 0.95,
+        "0.99" = 0.99
+      )
+    }
+  ),
+  # dropcorr.cutoff = p_fct(levels = c(0.8, 0.9, 0.95, 0.99)),
+  # winsorizesimple.probs_high = p_fct(levels = c(0.999, 0.99, 0.98, 0.97, 0.90, 0.8)),
+  # winsorizesimple.probs_low = p_fct(levels = c(0.001, 0.01, 0.02, 0.03, 0.1, 0.2)),
+  # scaling
+  scale_branch.selection = p_fct(levels = c("uniformization", "scale")),
+  # filters
+  filter_branch.selection = p_fct(levels = c("jmi", "relief", "gausscovf3")),
+  # interaction
+  interaction_branch.selection = p_fct(levels = c("nop_interaction", "modelmatrix")),
+  # learner
+  regr.xgboost.alpha     = p_dbl(0.001, 100, logscale = TRUE),
+  regr.xgboost.max_depth = p_int(1, 20),
+  regr.xgboost.eta       = p_dbl(0.0001, 1, logscale = TRUE),
+  regr.xgboost.nrounds   = p_int(1, 5000),
+  regr.xgboost.subsample = p_dbl(0.1, 1)
+)
+
+
+# BENCHMARK ---------------------------------------------------------------
+# benchamrk
+mlr3_save_path = "data"
+for (i in 177:180) {
+  # 1:length(cvs)
+  # debug
+  # i = 177
+  print(i)
+
+  # get cv and task
+  cv_ = cvs[[i]]
+  task_ = tasks[[i]]
+
+  # get cv inner object
+  cv_inner = cv_$custom_inner
+  cv_outer = cv_$custom_outer
+  cat("Number of iterations fo cv inner is ", cv_inner$iters, "\n")
+
+  designs_cv_l = lapply(1:cv_inner$iters, function(j) {
+    # debug
+    # j = 1
+    print(cv_inner$id)
+
+    # with new mlr3 version I have to clone
+    task_inner = task_$clone()
+    task_inner$filter(c(cv_inner$train_set(j), cv_inner$test_set(j)))
+
+    # inner resampling
+    custom_ = rsmp("custom")
+    custom_$id = paste0("custom_", cv_inner$iters, "_", j)
+    custom_$instantiate(task_inner,
+                        list(cv_inner$train_set(j)),
+                        list(cv_inner$test_set(j)))
+
+    # objects for all autotuners
+    measure_ = msr("regr.mse")
+    tuner_ = tnr("random_search")
+    # tuner_   = tnr("hyperband", eta = 5)
+    # tuner_   = tnr("mbo")
+    term_evals = 10
+
+    # auto tuner rf
+    at_rf = auto_tuner(
+      tuner = tuner_,
+      learner = graph_rf,
+      resampling = custom_,
+      measure = measure_,
+      search_space = search_space_rf,
+      # terminator = trm("none")
+      term_evals = term_evals
+    )
+
+    # auto tuner xgboost
+    at_xgboost = auto_tuner(
+      tuner = tuner_,
+      learner = graph_xgboost,
+      resampling = custom_,
+      measure = measure_,
+      search_space = search_space_xgboost,
+      # terminator = trm("none")
+      term_evals = term_evals
+    )
+
+    # outer resampling
+    customo_ = rsmp("custom")
+    customo_$id = paste0("custom_", cv_inner$iters, "_", j)
+    customo_$instantiate(task_,
+                         list(cv_outer$train_set(j)),
+                         list(cv_outer$test_set(j)))
+
+    # nested CV for one round
+    design = benchmark_grid(
+      tasks = task_,
+      learners = list(at_rf, at_xgboost),
+      resamplings = customo_
+    )
+  })
+  designs_cv = do.call(rbind, designs_cv_l)
+
+  # populate registry with problems and algorithms to form the jobs
+  print("Benchmark")
+  bmr = benchmark(designs_cv, store_models = FALSE)
+
+  # save locally and to list
+  time_ = format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+  file_name = paste0("commodities-", i, "-", time_, ".rds")
+  saveRDS(bmr, file.path(mlr3_save_path, file_name))
+}
+
+# benchmark results
+bmr$score(msr("regr.mse"))
diff --git a/jobs.sh b/jobs.sh
index 3c91293..1ec33fb 100644
--- a/jobs.sh
+++ b/jobs.sh
@@ -3,7 +3,7 @@
 #PBS -N BondsJobs
 #PBS -l ncpus=1
 #PBS -l mem=2GB
-#PBS -J 30001-40000
+#PBS -J 40001-50000
 #PBS -o experiments/logs
 #PBS -j oe
 
diff --git a/gold_ml.R b/prepare_commodities.R
similarity index 98%
rename from gold_ml.R
rename to prepare_commodities.R
index dd89252..0c9fe1d 100644
--- a/gold_ml.R
+++ b/prepare_commodities.R
@@ -89,5 +89,6 @@ mom_width = 1:12
 mom_cols = paste0("m_", mom_width)
 dt[, (mom_cols) := lapply(mom_width, function(x) value / shift(value, x) - 1), by = var]
 
+# save
+fwrite(dt, "data/commodities_dt.csv")
 
-dt[, unique(var)]
diff --git a/results_com.R b/results_com.R
new file mode 100644
index 0000000..f052f96
--- /dev/null
+++ b/results_com.R
@@ -0,0 +1,153 @@
+library(data.table)
+library(mlr3verse)
+library(fs)
+library(duckdb)
+library(lubridate)
+library(PerformanceAnalytics)
+
+
+
+# commodity data ----------------------------------------------------------------
+
+
+
+# PREDICTIONS -------------------------------------------------------------
+# list files
+mlr3_save_path = file.path(file.path(getwd(), "data/results"))
+files = list.files("data/results", full.names = TRUE)
+
+# read benchmark results
+predictions_l = list()
+for (i in 1:length(files)) {
+  # debug
+  print(i)
+
+  # read banchmark results
+  bmr = readRDS(files[i])
+  gc()
+  bmr_dt = as.data.table(bmr)
+
+  # measures
+  source("Linex.R")
+  source("AdjLoss2.R")
+  source("PortfolioRet.R")
+  mlr_measures$add("linex", Linex)
+  mlr_measures$add("adjloss2", AdjLoss2)
+  mlr_measures$add("portfolio_ret", PortfolioRet)
+
+  # aggregate performances
+  # agg_ = bmr$aggregate(msrs(c("regr.mse", "regr.mae", "adjloss2", "linex", "portfolio_ret")))
+  # cols = c("task_id", "learner_id", "iters", colnames(agg_)[7:length(colnames(agg_))])
+  # agg_ = agg_[, learner_id := gsub(".*regr\\.|\\.tuned", "", learner_id)][, ..cols]
+
+  # get predictions
+  task_names = lapply(bmr_dt$task, `[[`, "id")
+  learner_names = lapply(bmr_dt$learner, `[[`, "id")
+  learner_names = gsub(".*\\.regr\\.|\\.tuned", "", learner_names)
+  predictions = lapply(bmr_dt$prediction, function(x) as.data.table(x))
+  predictions = lapply(seq_along(predictions), function(j)
+    cbind(task = task_names[[j]],
+          learner = learner_names[[j]],
+          predictions[[j]]))
+  predictions = rbindlist(predictions)
+
+  # merge backs and predictions
+  backend = bmr_dt$task[[1]]$backend$data(rows = 1:bmr_dt$task[[1]]$nrow,
+                                          cols = bmr_dt$task[[1]]$col_info[, id])
+  setnames(backend, "..row_id", "row_ids")
+  predictions = backend[predictions, on = c("row_ids")]
+
+  # select cols
+  cols = c("row_ids", "maturity", "task", "learner", "truth", "response", "date")
+  predictions = predictions[, ..cols]
+  predictions[, month := as.Date(date)]
+  predictions_l[[i]] = predictions
+}
+predictions = rbindlist(predictions_l)
+predictions[, horizont := as.integer(gsub(".*_", "", task))]
+predictions[, unique(task)]
+
+
+# BACKTEST ----------------------------------------------------------------
+# portfoli performance
+Performance <- function(dt) {
+  # dt = performance[2, returns][[1]]
+  xts_ = as.xts.data.table(dt[, .SD, .SDcols = 1:(ncol(dt)-1)])
+
+  cumRetx = Return.cumulative(xts_)
+  annRetx = Return.annualized(xts_, scale=12)
+
+  res = rbind(cumRetx, annRetx)
+  res = as.data.table(res, keep.rownames = "var")
+  res[, mat := dt[1, mat]]
+
+  # sharpex = SharpeRatio.annualized(x, scale=12)
+  # winpctx = length(x[x > 0])/length(x[x != 0])
+  # annSDx = sd.annualized(x, scale=12)
+
+  # DDs <- findDrawdowns(x)
+  # maxDDx = min(DDs$return)
+  # maxLx = max(DDs$length)
+
+  # Perf = c(cumRetx, annRetx, sharpex, winpctx, annSDx, maxDDx, maxLx)
+  # names(Perf) = c("Cumulative Return", "Annual Return","Annualized Sharpe Ratio",
+  #                 "Win %", "Annualized Volatility", "Maximum Drawdown", "Max Length Drawdown")
+  # return(Perf)
+}
+
+
+# backtest function
+backtest = function(task, mat) {
+  # task = backtest_dt[task == "m1_1"]
+  # mat = "m1_1"
+  predictions_wide = task[, .(month, learner, response)]
+  predictions_wide = dcast(predictions_wide, month ~ learner, value.var = "response")
+  predictions_wide[, res_sum := ranger + xgboost]
+  predictions_wide[, signal_ranger := ranger >= 0]
+  predictions_wide[, signal_xgboost := xgboost >= 0]
+  predictions_wide[, signal_sum := (xgboost + ranger) >= 0]
+  tlt_back = merge(tlt_m, predictions_wide, by = "month", all.x = TRUE, all.y = FALSE)
+  tlt_back = tlt_back[, `:=`(
+    strategy_ranger = returns * shift(signal_ranger),
+    strategy_xgboost = returns * shift(signal_xgboost),
+    signal_sum = returns * shift(signal_sum)
+  )]
+  cols = c("month", "returns", "strategy_ranger", "strategy_xgboost",
+           "signal_sum")
+  tlt_back = tlt_back[, ..cols]
+  tlt_back = na.omit(tlt_back)
+  tlt_back[, mat := mat]
+  # tlt_back = na.omit(as.xts.data.table(tlt_back))
+  # colnames(tlt_back) = paste0(colnames(tlt_back), "_", task[1, 2])
+  tlt_back
+}
+
+# backtest grid
+performance = predictions[, .(returns = list(backtest(.SD, .BY))), by = "task"]
+performance = performance[, do.call(rbind, lapply(returns, Performance))]
+
+# individual backtests
+mat_ = predictions[, unique(task)][[5]]
+res = backtest(predictions[task == mat_], mat_)
+charts.PerformanceSummary(as.xts.data.table(res[, 1:5]))
+
+
+# BEST TASK ---------------------------------------------------------------
+# import benchmark results for best
+# bmr = readRDS(files[5])
+# gc()
+# bmr_dt = as.data.table(bmr)
+
+# check resamplings
+bmr_dt$resampling[[1]]$train_set(1)
+bmr_dt$resampling[[1]]$test_set(1)
+
+# last predictions
+last_predictions = predictions[task == "m12_1"][date == max(date)]
+last_predictions[, sum(response)]
+
+
+
+# PAPRE TRADE -------------------------------------------------------------
+
+

27957516e9c70a25d9069e6d6182b490be291e4c unknown Tue Jan 2 15:51:30 2024 +0100 new  arrays
diff --git a/gold_ml.R b/gold_ml.R
index 3f4500a..dd89252 100644
--- a/gold_ml.R
+++ b/gold_ml.R
@@ -1,29 +1,93 @@
 library(jsonlite)
 library(data.table)
+library(janitor)
+library(forecast)
+library(lubridate)
 
 
 
-# GOLD DATA ---------------------------------------------------------------
-# source: https://datahub.io/core/gold-prices#r
-# https://github.com/datasets/gold-prices
-json_file <- 'https://datahub.io/core/gold-prices/datapackage.json'
-json_data <- fromJSON(paste(readLines(json_file), collapse=""))
+# IMPORT DATA -------------------------------------------------------------
+# import commodity prices
+commodity_prices = fread("data/commodity_prices.csv")
+commodity_prices = clean_names(commodity_prices)
+commodity_prices[, month := as.Date(paste(gsub("M", "", month), "01"), format = "%Y%m%d")]
 
-# get list of all resources:
-print(json_data$resources$name)
+# wide to long
+dt = melt(commodity_prices, id.vars = "month", variable.name = "var")
 
-# print all tabular data(if exists any)
-for(i in 1:length(json_data$resources$datahub$type)){
-  if(json_data$resources$datahub$type[i]=='derived/csv'){
-    path_to_file = json_data$resources$path[i]
-    data <- read.csv(url(path_to_file))
-    print(data)
-  }
-}
 
-# convert to data.table
-dt = as.data.table(data)
+# TARGETS -----------------------------------------------------------------
+# calculate future returns
+dt[, target_ret_1 := shift(value, -1, type = "shift") / value, by = var]
+dt[, target_ret_3 := shift(value, -3, type = "shift") / value, by = var]
+dt[, target_ret_6 := shift(value, -6, type = "shift") / value, by = var]
+dt[, target_ret_12 := shift(value, -12, type = "shift") / value, by = var]
 
 
+# MACRO DATA --------------------------------------------------------------
+# import fred series
+fred_dt = fread("C:/macro/fred.csv")
 
-WORLD BANK !!!
+# remove unnecessary columns
+fred_dt = fred_dt[, .(series_id, date = date_real, frequency_short, popularity,
+                      units, id_category, value)]
+
+# diff if necessary
+fred_dt = fred_dt[, ndif := ndiffs(value), by = series_id]
+fred_dt[, unique(ndif), by = series_id][, .N, by = V1]
+fred_dt[ndif > 0, value_diff := c(rep(NA, unique(ndif)), diff(value, unique(ndif))), by = series_id]
+
+# check for duplicates
+date_series = fred_dt[, .N, by = .(date, series_id)]
+fred_dt = unique(fred_dt, fromLast = TRUE, by = c("series_id", "date"))
+rm(date_series)
+
+# downsample to monthly frequency
+fred_dt[, month := ceiling_date(date, "month")]
+fred_dt = fred_dt[, tail(.SD, 1), by = c("series_id", "month")]
+
+# reshape
+fred_dt = dcast(fred_dt[, .(month, series_id, value_diff)],
+                month ~ series_id,
+                value.var = "value_diff")
+setnames(fred_dt, "month", "date")
+setorder(fred_dt, date)
+fred_dt[1:10, 1:10]
+
+# remove predictors that doesnt have data for last year
+na_check_last_year = colSums(is.na(tail(fred_dt, 12)))
+fred_dt = fred_dt[, .SD, .SDcols = na_check_last_year < 12]
+
+# locf vars
+predictors = colnames(fred_dt)[2:ncol(fred_dt)]
+fred_dt[, (predictors) := lapply(.SD, nafill, type = "locf"), .SDcols = predictors]
+
+# lag all variables - IMPORTANT !
+# fred_dt[, (predictors) := lapply(.SD, shift), .SDcols = predictors]
+
+# filter dates
+fred_dt = fred_dt[date >= dt[, min(month)]]
+fred_dt[1:10, 1:10]
+
+# check for missing values
+na_check = colSums(is.na(fred_dt))
+sum(na_check == 0)
+fred_dt[, .SD, .SDcols = na_check == 0]
+fred_dt_sample = fred_dt[, .SD, .SDcols = na_check == 0]
+
+# predictors fred
+predictors_fred = colnames(fred_dt_sample)[2:ncol(fred_dt_sample)]
+
+
+# PREDICTORS --------------------------------------------------------------
+# merge yields and macro data
+dt = merge(dt, fred_dt_sample, by.x = "month", by.y = "date", all.x = TRUE, all.y = FALSE)
+
+# momentum predictors
+setorder(dt, var, month)
+mom_width = 1:12
+mom_cols = paste0("m_", mom_width)
+dt[, (mom_cols) := lapply(mom_width, function(x) value / shift(value, x) - 1), by = var]
+
+
+dt[, unique(var)]
diff --git a/jobs.sh b/jobs.sh
index 39d2320..3c91293 100644
--- a/jobs.sh
+++ b/jobs.sh
@@ -3,7 +3,7 @@
 #PBS -N BondsJobs
 #PBS -l ncpus=1
 #PBS -l mem=2GB
-#PBS -J 20001-30000
+#PBS -J 30001-40000
 #PBS -o experiments/logs
 #PBS -j oe
 
